---
description: 
globs: 
alwaysApply: true
---
# AI Agent Collaboration Patterns

This rule establishes systematic patterns for AI agents working on this project, ensuring consistent tool usage, documentation standards, and collaboration frameworks based on patterns documented in [AI_AGENT_COLLABORATION_GUIDE.md](mdc:docs/AI_AGENT_COLLABORATION_GUIDE.md).

## **Project Context Priority**

**When starting any new session, immediately understand:**
- **Project Type**: n8n Ultimate - AI-powered workflow generation system
- **Current Phase**: Phase 2 - User-friendly production experience  
- **Core Technologies**: Node.js, TypeScript, n8n API, Task Master AI
- **Local AI Models**: PHI4 (main), DeepSeek R1 (research), Claude Sonnet (fallback)
- **Zero-Cost Operation**: Task management using local Ollama models

## **Task Master Integration Patterns**

### **âœ… DO: Systematic Task Master Usage**

**Session Initialization:**
```bash
# 1. Check current tasks and status
mcp_task-master-ai_get_tasks

# 2. Identify next task to work on
mcp_task-master-ai_next_task

# 3. Get detailed task context
mcp_task-master-ai_get_task --id=<task-id>
```

**During Implementation:**
```bash
# Start working on a task
mcp_task-master-ai_set_task_status --id=<id> --status=in-progress

# Log detailed progress with timestamps
mcp_task-master-ai_update_subtask --id=<subtask-id> --prompt="
Implementation Progress Update:
- Explored codebase structure in src/dashboard/
- Identified files needing modification: dashboard/index.ts, user-guide/
- Planned approach: Progressive disclosure pattern
- Challenges discovered: Need to integrate with existing template system
"

# Mark completion with verification
mcp_task-master-ai_set_task_status --id=<id> --status=done
```

### **âŒ DON'T: Task Master Anti-Patterns**
```bash
# Don't work without task context
# Don't skip progress logging
# Don't mark tasks done without verification
# Don't create tasks without proper description/dependencies
```

## **5-Phase Systematic Methodology**

Apply this to ALL development work:

### **Phase 1: IDENTIFY**
- **Task Context**: Use `get_task` to understand requirements fully.
- **Codebase Analysis**: Run `WorkflowValidator` and `DataFlowValidator` from `src/validation` to automatically identify structural and data flow issues. Examine existing patterns and architecture.
- **Dependency Check**: Verify all prerequisite tasks are complete.
- **Scope Definition**: Clear boundaries of what needs to be accomplished.

### **Phase 2: ISOLATE**
- **Component Focus**: Identify specific files/functions to modify. Use `NodeAnalyzer` from `src/utils` to understand node dependencies.
- **Pattern Recognition**: Look for existing similar implementations to reuse.
- **Risk Assessment**: Identify potential breaking changes.
- **Test Strategy**: Plan verification approach using the `RealWorldTestingFramework` from `src/testing`.

### **Phase 3: FIX/IMPLEMENT**
- **Progressive Implementation**: Start with smallest working change.
- **Pattern Consistency**: Use `WorkflowGenerator` from `src/generators` to ensure new nodes and connections follow established project patterns.
- **Error Handling**: Implement `ErrorClassifier` and `AdaptiveErrorCollector` from `src/error-handling` instead of generic try-catch blocks.
- **Documentation**: Update relevant documentation inline.

### **Phase 4: VERIFY**
- **Unit Level**: Test individual functions/components.
- **Integration Level**: Test interactions between components.
- **System Level**: Use the `RealWorldTestingFramework` from `src/testing` to simulate real-world scenarios and test complete feature functionality.
- **Edge Cases**: Use the `ErrorTestingFramework` from `src/error-handling` to test error scenarios and boundary conditions.

### **Phase 5: DOCUMENT**
- **Task Master Updates**: Log all findings and decisions.
- **Rule Updates**: Update rules based on new patterns.
- **Execution Log**: Update project execution log.
- **Knowledge Preservation**: Ensure future agents can understand decisions.
- **Patterns**: Follows established project patterns.
- **Performance**: No performance regressions. Validated with `PerformanceMonitor` from `src/performance`.
- **Task Master**: Progress fully logged.

## **Code Development Patterns**

### **âœ… DO: Systematic Code Implementation**

**File Organization:**
```typescript
// Follow established project structure
src/
  dashboard/           // UI components with progressive disclosure
  ai-agents/          // AI integration patterns
  error-handling/     // Comprehensive error management
  performance/        // Optimization and caching
  testing/           // Real-world testing framework
```

**Error Handling Pattern:**
```typescript
// Always include comprehensive error handling
try {
  const result = await performOperation(data);
  
  // Log success patterns for learning
  logger.info('Operation successful', { 
    operation: 'workflow-generation',
    data: sanitizedData,
    result: result.id 
  });
  
  return result;
} catch (error) {
  // Log error patterns for debugging
  logger.error('Operation failed', {
    operation: 'workflow-generation',
    error: error.message,
    data: sanitizedData,
    timestamp: new Date().toISOString()
  });
  
  throw new WorkflowGenerationError(
    `Failed to generate workflow: ${error.message}`,
    { originalError: error, data }
  );
}
```

### **âœ… COMPREHENSIVE TESTING & DEMO FRAMEWORK PATTERNS**

**Established Pattern (January 2025): Automated Workflow Analysis**
When users report issues like "nodes are unlinked" or connection problems:

**Testing Script Pattern:**
```javascript
// âœ… DO: Create comprehensive automated testing scripts
// File: scripts/test-workflow-execution.js

// 1. Node Structure Analysis
const nodeMap = new Map();
workflow.nodes.forEach(node => {
    nodeMap.set(node.id, node);
    console.log(`â€¢ ${node.name} (${node.type}) - ID: ${node.id}`);
});

// 2. Connection Validation
Object.entries(workflow.connections).forEach(([sourceId, connections]) => {
    const sourceNode = nodeMap.get(sourceId);
    connections.main?.forEach(connectionGroup => {
        connectionGroup.forEach(connection => {
            const targetNode = nodeMap.get(connection.node);
            if (!targetNode) {
                connectionIssues.push(`âŒ Target node not found: ${connection.node}`);
            } else {
                console.log(`  âœ… â†’ ${targetNode.name}`);
            }
        });
    });
});

// 3. Execution Flow Tracing
function traceExecution(nodeId, depth = 0) {
    const node = nodeMap.get(nodeId);
    if (!node) return;
    
    executionPath.push(`${'  '.repeat(depth)}${depth + 1}. ${node.name}`);
    
    const nodeConnections = workflow.connections[nodeId];
    if (nodeConnections?.main) {
        nodeConnections.main.forEach(connectionGroup => {
            connectionGroup.forEach(connection => {
                traceExecution(connection.node, depth + 1);
            });
        });
    }
}

// 4. AI Service Integration Testing
async function testAIService() {
    try {
        const response = await fetch('http://localhost:3000/summarize-error', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                error: 'Test workflow execution error',
                workflow: 'test-integration',
                timestamp: new Date().toISOString()
            })
        });
        
        if (response.ok) {
            console.log('âœ… AI service integration working');
        }
    } catch (error) {
        console.log('âŒ AI service not available:', error.message);
    }
}
```

**Demo Script Pattern:**
```bash
# âœ… DO: Create comprehensive demo scripts
# File: scripts/demo-ai-workflow.sh

#!/bin/bash
echo "ðŸŽ¯ n8n Ultimate AI Workflow Demo"

# 1. Service Status Verification
if curl -s http://localhost:3000/health > /dev/null 2>&1; then
    echo "âœ… AI service running on localhost:3000"
else
    echo "âŒ AI service not running. Please start with: npm start"
    exit 1
fi

# 2. Error Analysis Demonstrations
echo "ðŸ§  Testing AI-Powered Error Analysis..."

# Test Rate Limiting Errors
curl -X POST http://localhost:3000/summarize-error \
  -H "Content-Type: application/json" \
  -d '{"error":"Rate limiting error (429): Too many requests","workflow":"hubspot-mixpanel","timestamp":"2025-01-23T08:32:00Z"}'

# Test Authentication Errors  
curl -X POST http://localhost:3000/summarize-error \
  -H "Content-Type: application/json" \
  -d '{"error":"Authentication failed (401): Invalid API token for Mixpanel","workflow":"hubspot-mixpanel","timestamp":"2025-01-23T08:32:00Z"}'

# 3. Feature Showcase
echo "âœ¨ Key AI-Enhanced Features in Your Workflow:"
echo "ðŸ”§ 1. AI-Enhanced Contact Aggregation"
echo "ðŸŒ 2. AI-Powered Page View Processing"
echo "ðŸ›¡ï¸ 3. Enhanced AI Error Handler"
echo "ðŸ“Š 4. AI Execution Logger"

# 4. Integration Point Validation
echo "ðŸ”— localhost:3000 Integration Points:"
echo "â€¢ /analyze-engagement - Real-time engagement analysis"
echo "â€¢ /report-error - Enhanced error reporting"
echo "â€¢ /analyze-errors - Batch error analysis"
echo "â€¢ /log-execution - Execution metrics logging"

echo "ðŸŽ¯ Demo Complete! ðŸš€"
```

**Visual vs Structural Issue Diagnosis:**
```javascript
// âœ… DO: Distinguish visual from structural problems
// When users report "unlinked nodes":

// 1. FIRST: Run automated validation
const connectionIssues = validateConnections(workflow);

// 2. Report findings clearly
if (connectionIssues.length === 0) {
    console.log('âœ… All connections are valid!');
    console.log('ðŸ“Š This appears to be a visual display issue in n8n UI');
    console.log('ðŸ’¡ Solution: Refresh workflow or re-import JSON');
    console.log('ðŸ” The workflow structure is completely functional');
} else {
    console.log('âŒ Actual connection issues found:');
    connectionIssues.forEach(issue => console.log(`  ${issue}`));
}
```

**Task Master Integration for Complex Demos:**
```bash
# âœ… DO: Use Task Master systematically during complex demos
# Track demo progress and findings

mcp_task-master-ai_update_subtask --id=<demo-subtask> --prompt="
DEMO PROGRESS UPDATE:
- **Testing Framework**: Created comprehensive automated validation scripts
- **Connection Analysis**: Verified all 9 connections properly defined using node IDs
- **AI Integration**: Tested all localhost:3000 endpoints successfully
- **Visual vs Structural**: Confirmed UI display issue vs actual functionality
- **User Education**: Explained distinction between cosmetic and structural problems
- **Documentation**: Created comprehensive testing and demo framework
- **Status**: Demo completed successfully, all features validated
"

# Mark completion with verification
mcp_task-master-ai_set_task_status --id=<demo-task> --status=done
```

## **Quality Standards**

### **Code Quality Gates**
Before marking any task complete:
- [ ] **Functionality**: Feature works as specified
- [ ] **Error Handling**: Comprehensive error management
- [ ] **Testing**: Unit and integration tests pass
- [ ] **Documentation**: Inline and external docs updated
- [ ] **Patterns**: Follows established project patterns
- [ ] **Performance**: No performance regressions
- [ ] **Task Master**: Progress fully logged

### **Documentation Quality Gates**
- [ ] **Clarity**: Clear, actionable instructions
- [ ] **Completeness**: All aspects covered
- [ ] **Examples**: Real code examples included
- [ ] **Context**: Links to related documentation
- [ ] **Maintenance**: Easy to update and extend

## **AI Agent Handoff Patterns**

### **Session Startup Checklist**
```bash
# 1. Load project context
mcp_task-master-ai_get_tasks --withSubtasks=true

# 2. Check execution log
# Read: Execution Log for AI helper.txt

# 3. Review recent progress
mcp_task-master-ai_get_task --id=<last-active-task>

# 4. Understand current phase
# Check: docs/PROJECT_OVERVIEW.md, docs/Roadmap.md
```

## **Tool Integration Priority Order**

1.  **Task Master (Primary)**: For systematic task and progress management.
2.  **Internal Validation & Analysis Suite (`src/validators`, `src/utils`, `src/validation`)**: Before any manual analysis, use our full validation suite:
    -   `WorkflowValidator`, `DataFlowValidator`, `ConnectionValidator`: For structural and data flow integrity.
    -   `ErrorHandlingValidator`: To ensure robust error handling is in place.
    -   `NodeCompatibilityValidator`, `PerformanceValidator`: For node-specific and performance checks.
    -   `NodeAnalyzer`: To understand node dependencies and relationships.
3.  **Skeleton Analysis & Enhancement (`src/skeleton-analyzer.ts`, `src/skeleton-enhancer.ts`)**:
    -   `SkeletonAnalyzer`: For deconstructing and understanding existing workflows.
    -   `SkeletonEnhancer`: To apply learned patterns and improvements to new or existing skeletons.
4.  **AI-Powered Generation & Enhancement (`src/generators`, `src/ai-agents`)**:
    -   `WorkflowGenerator` and `OptimizedAIAgent`: For creating and enhancing workflows.
    -   `AIAgent` (`src/ai-agents/ai-agent.ts`): To be used for more complex, multi-step generation tasks that require conversational context.
5.  **Automated Error Handling (`src/error-handling`)**:
    -   `ErrorClassifier`, `ErrorRecoveryManager`: For classifying and managing errors.
    -   `AdaptiveErrorCollector`: To dynamically gather context around failures.
    -   `PerformanceAwareErrorHandler`: To handle performance-related errors gracefully.
6.  **Performance Tooling (`src/performance`)**:
    -   `PerformanceMonitor`, `IntelligentCacheManager`: For optimization tasks.
    -   `DatabaseIoOptimizer`, `MemoryManager`: For resource-specific optimizations.
    -   `DatadogPerformanceConnector`: To pipe performance data to external monitoring services.
7.  **Real-World & Learning-Based Testing (`src/testing`)**:
    -   `RealWorldTestingFramework`: For all verification steps.
    -   `ComprehensiveLearningTestingFramework`: To validate that the system learns from new data and patterns correctly.
    -   `ErrorTestingFramework`: To test error scenarios and boundary conditions.
8.  **Knowledge Management (`src/integration`, `src/community`)**:
    -   `KnowledgeManagementSystem`: To store and retrieve learnings.
    -   `CommunityNodeValidator`: To validate and integrate community nodes safely.
9.  **AI Research (Secondary)**: Use for external knowledge gathering when internal tools lack context.
10. **Manual Code Analysis (Fallback)**: Use `codebase_search` and manual file reading only when automated tools are insufficient.

## **Emergency Patterns**

### **When Things Break**
1. **Immediate**: Run `WorkflowValidator`, `DataFlowValidator`, and `ErrorClassifier` from `src/` to diagnose the issue. Use n8n debugging methodology from rules as a fallback.
2. **Document**: Log in Task Master with full context from the tool outputs.
3. **Fix**: Apply systematic 5-phase approach, using `WorkflowGenerator` to implement fixes.
4. **Verify**: Use the `RealWorldTestingFramework` to test the fix thoroughly.
5. **Learn**: Update rules with new patterns discovered.

### **When Context is Lost**
1. **Task Master**: `get_tasks` to understand current state.
2. **Execution Log**: Read recent entries for context.
3. **Documentation**: Review relevant docs/ files.
4. **Code Analysis**: Examine recent changes and patterns.
5. **Systematic Approach**: Apply 5-phase methodology.

## **References**

- [AI_AGENT_COLLABORATION_GUIDE.md](mdc:docs/AI_AGENT_COLLABORATION_GUIDE.md) - Complete collaboration guide
- [N8N_WORKFLOW_DEBUGGING.md](mdc:docs/N8N_WORKFLOW_DEBUGGING.md) - Debugging methodology
- [taskmaster.mdc](mdc:.cursor/rules/taskmaster.mdc) - Complete tool reference
- [Execution Log for AI helper.txt](mdc:Execution Log for AI helper.txt) - Project history

---

*This framework ensures every AI agent can immediately understand the project context, apply consistent methodologies, and maintain the high quality standards established for n8n Ultimate.*

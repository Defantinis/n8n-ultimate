---
description: 
globs: 
alwaysApply: true
---
# n8n Workflow Debugging Methodology

This rule establishes the systematic 5-phase debugging approach for n8n workflows, based on real-world patterns and solutions documented in [N8N_WORKFLOW_DEBUGGING.md](mdc:docs/N8N_WORKFLOW_DEBUGGING.md).

## **Core Debugging Philosophy**

- **Field Name Consistency**: The #1 cause of n8n workflow failures
- **Progressive Testing**: Individual nodes ‚Üí connections ‚Üí end-to-end
- **Error Pattern Recognition**: HTTP 500 errors have predictable root causes
- **Graceful Degradation**: Always include comprehensive error handling
- **Visual vs Structural Validation**: n8n UI display issues don't indicate actual connection problems

## **CRITICAL: n8n Node Connection Methodology (NEVER FORGET)**

### **‚úÖ MANDATORY CONNECTION PATTERNS**

**How n8n Connections Actually Work:**
```json
{
  "connections": {
    "SOURCE_NODE_ID": {
      "main": [
        [
          {
            "node": "TARGET_NODE_ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}
```

**CRITICAL RULES:**
1. **ALWAYS use node IDs, NEVER node names** in connections
2. **Each node MUST have a unique ID** (UUID format)
3. **Connections reference the "id" field**, not "name" field
4. **Visual display ‚â† actual connections** - UI can lie, JSON doesn't

### **‚úÖ ESTABLISHED PATTERN: Visual Display Issues Are Cosmetic**
Based on comprehensive testing (January 2025), when users report "nodes are unlinked" in n8n:

**Root Cause Analysis:**
- **Visual Issue**: n8n UI sometimes doesn't render connections properly
- **Structural Reality**: JSON connections are properly defined using node IDs
- **False Alarm**: Workflow functionality remains intact despite visual appearance

**Connection Validation Pattern:**
```javascript
// ‚úÖ DO: Validate connections using node IDs
const nodeMap = new Map();
workflow.nodes.forEach(node => {
    nodeMap.set(node.id, node);
});

// Check each connection references valid node IDs
Object.entries(workflow.connections).forEach(([sourceId, connections]) => {
    const sourceNode = nodeMap.get(sourceId);
    if (!sourceNode) {
        console.log(`‚ùå Source node not found: ${sourceId}`);
        return;
    }
    
    connections.main?.forEach(connectionGroup => {
        connectionGroup.forEach(connection => {
            const targetNode = nodeMap.get(connection.node);
            if (!targetNode) {
                console.log(`‚ùå Target node not found: ${connection.node}`);
            } else {
                console.log(`‚úÖ ${sourceNode.name} ‚Üí ${targetNode.name}`);
            }
        });
    });
});

// ‚ùå DON'T: Assume visual = structural problem
// Don't rebuild workflows based on UI display alone
// Don't panic when connections appear unlinked visually
```

### **‚úÖ CONNECTION CREATION PATTERNS**

**When Adding New Connections:**
```json
// ‚úÖ DO: Use proper node ID structure
"connections": {
  "e1cb4471-9ecd-41cf-8967-42b0e7151548": {
    "main": [
      [
        {
          "node": "1124e4b4-8f06-4a46-a53e-fe6cad1f3ee7",
          "type": "main", 
          "index": 0
        }
      ]
    ]
  }
}

// ‚ùå DON'T: Use node names
"connections": {
  "Workflow Config": {  // WRONG - this is a name, not ID
    "main": [...]
  }
}
```

**Multiple Output Connections:**
```json
// ‚úÖ DO: Multiple targets from one source
"ab87b45a-3c76-4966-9c1b-db5d6c17c8f9": {
  "main": [
    [
      {
        "node": "01428357-7f55-4474-8f73-aef1d7799cd5",
        "type": "main",
        "index": 0
      },
      {
        "node": "f332c233-2c0c-4538-b017-406a052854d2", 
        "type": "main",
        "index": 0
      }
    ]
  ]
}
```

**Validation Pattern:**
```bash
# Systematic connection analysis using automated tools
node scripts/test-workflow-execution.js

# Expected output for healthy workflow:
# ‚úÖ All connections are valid!
# üìä Connection Summary: X connections, 0 issues
# üöÄ Status: Ready for execution
```

### **‚úÖ COMPREHENSIVE TESTING FRAMEWORK PATTERN**
**Established Testing Methodology:**
1. **Automated Workflow Tester** (`scripts/test-workflow-execution.js`)
   - Node structure analysis with type and ID mapping
   - Connection validation using proper node references
   - Execution flow tracing from trigger to completion
   - AI service integration endpoint testing

2. **AI Feature Demo Script** (`scripts/demo-ai-workflow.sh`)
   - Error analysis demonstrations (rate limiting, auth, data processing)
   - Feature showcase with real examples
   - Integration validation for all localhost service endpoints

**Implementation Pattern:**
```javascript
// ‚úÖ DO: Systematic workflow analysis
const nodeMap = new Map();
workflow.nodes.forEach(node => nodeMap.set(node.id, node));

// Validate connections use node IDs, not names
connections.main?.forEach(connectionGroup => {
    connectionGroup.forEach(connection => {
        const targetNode = nodeMap.get(connection.node);
        if (!targetNode) {
            connectionIssues.push(`‚ùå Target node not found: ${connection.node}`);
        }
    });
});
```

## **5-Phase Debugging Methodology**

### **Phase 1: IDENTIFY**
- **Automated Analysis**: Run `WorkflowValidator`, `DataFlowValidator`, and `ConnectionValidator` from `src/validation` to automatically detect common issues.
- **Error Classification**: Use `ErrorClassifier` from `src/error-handling` to understand the root cause of any exceptions.
- **Visual vs Structural**: Use automated testing scripts to distinguish UI display issues from actual connection problems.
- **HTTP 500 Errors**: Check trigger configuration, field mappings, HTTP parameters.
- **Node Failures**: Verify node-specific requirements (credentials, parameters, data types).
- **Data Flow Issues**: Trace data transformation between connected nodes.
- **Field Consistency**: Look for mismatched field names across the workflow.

### **Phase 2: ISOLATE**
- **Node Analysis**: Use `NodeAnalyzer` from `src/utils` to identify the specific node and its dependencies that are causing the failure.
- **Connection Verification**: Create comprehensive test scripts to validate actual JSON structure vs visual display.
- **Targeted Testing**: Test the isolated component with the `RealWorldTestingFramework` using sample data that replicates the error.
```javascript
// ‚úÖ DO: Test individual components with automated tools
// Use NodeAnalyzer to find the problematic node
// Use RealWorldTestingFramework to test it with specific data
// Use automated connection validation scripts

// ‚ùå DON'T: Test entire workflow at once
// Skip individual node validation
// Assume data flow without verification
// Trust visual display over JSON structure analysis
```

### **Phase 3: FIX**
**Critical Fix Patterns:**
- **Automated Generation**: Use `WorkflowGenerator` from `src/generators` to rebuild faulty nodes or connections according to best practices.
- **Visual Linking Issues**: Refresh workflow in n8n or re-import JSON if connections appear unlinked but JSON structure is valid.
- **Schedule Triggers**: Always include complete cron configuration.
- **HTTP Requests**: Specify method, headers, and parameter structure.
- **Field References**: Use consistent naming (customer_id vs mixpanel_customer_id).
- **Data Transformations**: Handle undefined/null values gracefully, preferably with logic from our `ai-agents`.

### **Phase 4: VERIFY**
- **Automated Validation**: Re-run all validators from `src/validation` to confirm the fix has not introduced new issues.
- **Comprehensive Testing**: Use automated testing scripts to verify all connections and execution flow.
- **Individual Node Testing**: Each node executes successfully in isolation.
- **Connection Testing**: Data flows correctly between connected nodes.
- **End-to-End Testing**: Use the `RealWorldTestingFramework` to execute the complete workflow with the original problematic data.
- **Error Scenarios**: Use the `ErrorTestingFramework` to test for graceful handling of edge cases and failures.
- **AI Service Integration**: Test all localhost service endpoints for proper integration.

### **Phase 5: DOCUMENT**
- **Update Task Master**: Log findings using `update_subtask` with timestamps, including the output from our analysis tools.
- **Pattern Documentation**: Record successful patterns and fixes in `docs/LEARNINGS.md` for future reference.
- **Error Solutions**: Document specific fixes for common error patterns.
- **Testing Framework**: Document automated testing scripts and their usage patterns.
- **Visual vs Structural**: Document the distinction between UI display issues and actual problems.

## **AI Service Integration Testing Patterns**

### **‚úÖ ESTABLISHED AI INTEGRATION VALIDATION**
**Service Endpoint Testing:**
```bash
# Test AI service availability and functionality
curl -X POST http://localhost:3000/summarize-error \
  -H "Content-Type: application/json" \
  -d '{"error":"Test error","workflow":"test","timestamp":"2025-01-23T08:32:00Z"}'

# Expected: Intelligent error analysis response
# Validates: AI service integration working properly
```

**Integration Points to Test:**
- `/summarize-error` - Intelligent error analysis
- `/analyze-engagement` - Real-time engagement scoring  
- `/report-error` - Enhanced error reporting
- `/log-execution` - Comprehensive execution metrics

### **‚úÖ COMPREHENSIVE DEMO FRAMEWORK PATTERN**
**Automated Demo Script Structure:**
```bash
#!/bin/bash
# 1. Service status verification
# 2. Error analysis demonstrations (rate limiting, auth, data processing)
# 3. Feature showcase with real examples
# 4. Integration point validation
# 5. Comprehensive status reporting
```

## **Field Name Consistency Patterns**

### **‚úÖ DO: Consistent Field Naming**
```json
{
  "customer_id": "12345",           // Use throughout workflow
  "mixpanel_customer_id": "12345",  // Explicit mapping when needed
  "contact_id": "67890"             // Clear, consistent naming
}
```

### **‚ùå DON'T: Inconsistent Field References**
```json
{
  "customerId": "12345",      // CamelCase
  "customer_id": "12345",     // Snake_case  
  "CustomerID": "12345"       // PascalCase
}
```

## **HTTP Node Configuration Patterns**

### **‚úÖ DO: Complete HTTP Configuration**
```json
{
  "method": "GET",
  "url": "https://api.example.com/endpoint",
  "headers": {
    "Authorization": "Bearer {{$credentials.token}}",
    "Content-Type": "application/json"
  },
  "qs": {
    "param1": "{{$json.field1}}",
    "param2": "{{$json.field2}}"
  }
}
```

### **‚ùå DON'T: Incomplete HTTP Configuration**
```json
{
  "url": "https://api.example.com/endpoint"
  // Missing method, headers, parameters
}
```

## **‚úÖ CRITICAL: Code Node Return Format (NEVER FORGET)**

### **‚úÖ MANDATORY: Proper Code Node Return Structure**

**The #1 Cause of "Code doesn't return items properly" Error:**
```javascript
// ‚ùå WRONG: Basic return (causes error)
return $input.all();

// ‚ùå WRONG: Direct object return (causes error)  
return { data: processedData };

// ‚úÖ CORRECT: Array of objects with json property
return [{ 
  json: {
    processed_data: result,
    timestamp: new Date().toISOString(),
    // ... your data here
  }
}];

// ‚úÖ CORRECT: Multiple items
return processedItems.map(item => ({
  json: {
    ...item,
    processed: true
  }
}));
```

### **‚úÖ CRITICAL: Modern n8n Code Node Parameters**

**Parameter Evolution (CRITICAL TO REMEMBER):**
```json
// ‚ùå OLD (n8n < 1.0): Causes "Code doesn't return items properly"
{
  "parameters": {
    "jsCode": "// old parameter name"
  }
}

// ‚úÖ NEW (n8n 1.0+): Modern parameter structure
{
  "parameters": {
    "code": "// modern parameter name"
  }
}
```

### **‚úÖ CRITICAL: Node Reference Syntax Updates**

**Syntax Evolution (CAUSES CONNECTION FAILURES):**
```javascript
// ‚ùå DEPRECATED (causes "Cannot read properties of undefined"):
const data = $node['Node Name'].json;
const config = $node['Workflow Config'].json.setting;

// ‚úÖ MODERN (works in all n8n versions):
const data = $('Node Name').json;
const config = $('Workflow Config').json.setting;
```

## **Error Handling Patterns**

### **‚úÖ DO: Comprehensive Error Handling**
```javascript
// In Code nodes - ALWAYS return proper format
try {
  const processedData = [];
  
  for (const item of $input.all()) {
    const data = item.json;
    
    // Validate required fields
    if (!data.customer_id) {
      processedData.push({
        json: {
          error: 'Missing customer_id',
          original_data: data,
          timestamp: new Date().toISOString()
        }
      });
      continue;
    }
    
    // Process data
    processedData.push({
      json: {
        processed: true,
        customer_id: data.customer_id,
        result: processData(data),
        timestamp: new Date().toISOString()
      }
    });
  }
  
  return processedData;
} catch (error) {
  return [{
    json: {
      error: error.message,
      timestamp: new Date().toISOString(),
      stack: error.stack
    }
  }];
}
```

## **Task Master Integration**

When debugging n8n workflows, use Task Master systematically:

```bash
# Log debugging progress
mcp_task-master-ai_update_subtask --id=<subtask-id> --prompt="
Phase 1 IDENTIFY: Found HTTP 500 error in HubSpot node
- **WorkflowValidator Output**: [Paste output here]
- **ErrorClassifier Output**: [Paste output here]
- **Automated Testing Results**: [Paste connection validation results]
- Root cause: Missing customer_id field mapping
- Affected nodes: HubSpot Contact Fetch, Mixpanel Update
- Error pattern: Field name inconsistency
- Visual vs Structural: JSON structure valid, UI display issue only
"

# Mark phases complete
mcp_task-master-ai_set_task_status --id=<subtask-id> --status=done
```

## **Quality Gates**

Before marking any n8n workflow task complete:
- [ ] All validators from `src/validation` pass
- [ ] Automated testing scripts confirm connection validity
- [ ] All HTTP 500 errors resolved
- [ ] Field name consistency verified
- [ ] Error handling implemented using `src/error-handling` tools
- [ ] End-to-end testing passed with `RealWorldTestingFramework`
- [ ] AI service integration tested and validated
- [ ] Visual vs structural issues properly diagnosed
- [ ] Documentation updated with testing results
- [ ] Task Master progress logged with tool outputs

## **Emergency Diagnostic Checklist**

When users report "unlinked nodes" or connection issues:
1. **‚úÖ FIRST**: Run automated testing script (`scripts/test-workflow-execution.js`)
2. **‚úÖ VERIFY**: Check JSON structure for proper node ID references
3. **‚úÖ VALIDATE**: Confirm execution flow traces correctly
4. **‚úÖ TEST**: Verify AI service integration endpoints
5. **‚úÖ DOCUMENT**: Log findings in Task Master with test results
6. **‚úÖ REASSURE**: Explain visual vs structural distinction to user

## **References**

- [N8N_WORKFLOW_DEBUGGING.md](mdc:docs/N8N_WORKFLOW_DEBUGGING.md) - Complete debugging guide
- [AI_AGENT_COLLABORATION_GUIDE.md](mdc:docs/AI_AGENT_COLLABORATION_GUIDE.md) - Tool usage patterns
- [workflow-linking-and-testing-demo.md](mdc:docs/workflow-linking-and-testing-demo.md) - Comprehensive testing results

---

*This systematic approach ensures consistent, high-quality n8n workflow development and maintenance, with special attention to distinguishing visual display issues from actual structural problems.*
